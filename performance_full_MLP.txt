Emotion MLPClassifier(max_iter=1):{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
Confusion Matrix: 
[[1077   24    4    3   25    9    0    5   10    2    3    1    1    4
     0   40   30   74  751   19    0    0    3   36]
 [  42  688    7    7    2    0    2    4    4    0    2    1    0    1
     0    7   25   12  381    4    0    0    2    9]
 [  12   12  261   31    1    0    1    3    1    1   13   11    0    0
     3    4    5    2  633    3    0    2    6    4]
 [  28   39  107   61    9    8    4    6    2    5   35   15    1    1
     5   16    5   12 1268    9    0    7    6   14]
 [ 152   35   11   12  148   17    6    5    4    2   32    7    0    2
     5   19   20   30 1812   26    1    3    5   12]
 [  22    9    6    8    8   41    0    2    7    2    9    0    0    0
     5   13   17   15  496   33    0    6    5    4]
 [  11   15   12    6    5    0   72   30    1    0   11    1    0    0
     4    4    5    6  764    1    1    3    3    9]
 [  25   11   16    2    6    2    2  139    1    2    4    2    1    4
     3    2    1   10  907    7    0    3    2   23]
 [   8    8    1    0    3    1    0    4   85    0    1    0    0    1
     2    2    2    7  256   31    0    0    1    3]
 [  14    9   21   10    6    6    3    1    8   17   10    7    0    1
     3    3    1   11  776    5    1   14   19   11]
 [  18   24   36   22   28    5    6    2    6    7   69   10    0    1
     7   14    5   10 1231   10    1   10   12    8]
 [   6    3   48   12    3    0    1    1    1    5   10   98    0    0
     3    0    2    1  375    2    1    2    5    5]
 [   4    5   12    6    1    4    3    2    1    1    5    6    2    0
     1    0    0    2  229    0    0    6    5    4]
 [  66    8    6    1    4    2    0    6    4    0    0    0    0   47
     0    9   38   12  333   11    1    0    2   22]
 [   2    8    6    4    4    2    1    1    0    0    2    4    1    0
   110    0    1    1  217    3    0    2    1    2]
 [  90    8    1    0    5    1    0    0    3    0    1    0    0    0
     0 1067   29    9  131   21    0   25    3    2]
 [  58  106    3    1    8    0    0    1    4    1    2    0    0    2
     2   37  225   51  329    7    0    0    3   10]
 [  46   13    4    3    7    1    0    1    1    0    2    1    0    0
     0    7   13  655  275    2    0    3    3    0]
 [ 249  203  138   53   97   31   31   82   50   20   89   22    0   11
    28   67   79  135 9411   62   10   31   42   44]
 [  35   11    6    2   15   11    1    0   18    3    5    1    0    1
     1   16   12   13  472  248    0    1    6    6]
 [  18   16    9    7   13    1    4    2    1    7    9    2    0    1
     6    4    5    6  765    9   22   13    4   19]
 [   2    4    0    0    1    1    0    1    2    0    3    1    1    0
     0    4    0    1  125    0    0  152   10    2]
 [   4    7    8    5    3    5    0    0    6   10    6    3    0    1
     3    6    4    5  510    7    1   68  132    3]
 [  38    9   16    1    1    0    1   10    2    2    2    1    0    3
     0    4    7    5  448    3    2    1    1  154]]
Classification Report: 
                precision    recall  f1-score   support

    admiration       0.52      0.51      0.52      2121
     amusement       0.54      0.57      0.56      1200
         anger       0.35      0.26      0.30      1009
     annoyance       0.24      0.04      0.06      1663
      approval       0.36      0.06      0.11      2366
        caring       0.27      0.06      0.10       708
     confusion       0.52      0.07      0.13       964
     curiosity       0.45      0.12      0.19      1175
        desire       0.38      0.20      0.27       416
disappointment       0.19      0.02      0.03       957
   disapproval       0.21      0.04      0.07      1542
       disgust       0.51      0.17      0.25       584
 embarrassment       0.29      0.01      0.01       299
    excitement       0.58      0.08      0.14       572
          fear       0.56      0.30      0.39       372
     gratitude       0.78      0.76      0.77      1396
           joy       0.41      0.26      0.32       850
          love       0.60      0.63      0.62      1037
       neutral       0.40      0.86      0.55     10985
      optimism       0.47      0.28      0.35       884
   realization       0.54      0.02      0.04       943
       remorse       0.43      0.49      0.46       310
       sadness       0.45      0.17      0.24       797
      surprise       0.38      0.22      0.28       711

     micro avg       0.44      0.44      0.44     33861
     macro avg       0.43      0.26      0.28     33861
  weighted avg       0.42      0.44      0.37     33861

--------------------------------------------
Sentiment MLPClassifier(max_iter=1):{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
Confusion Matrix: 
[[ 761  599 1815  618]
 [ 184 4238 2455  882]
 [ 448 1783 6616 2138]
 [ 219  935 2834 7839]]
Classification Report: 
              precision    recall  f1-score   support

   ambiguous       0.47      0.20      0.28      3793
    negative       0.56      0.55      0.55      7759
     neutral       0.48      0.60      0.54     10985
    positive       0.68      0.66      0.67     11827

    accuracy                           0.57     34364
   macro avg       0.55      0.50      0.51     34364
weighted avg       0.57      0.57      0.56     34364

--------------------------------------------
Emotion GridSearchCV(estimator=MLPClassifier(max_iter=1),
             param_grid={'activation': ['logistic', 'tanh', 'relu', 'identity'],
                         'hidden_layer_sizes': [(30, 50), (10, 10, 10)],
                         'solver': ['sgd', 'adam']}):{'cv': None, 'error_score': nan, 'estimator__activation': 'relu', 'estimator__alpha': 0.0001, 'estimator__batch_size': 'auto', 'estimator__beta_1': 0.9, 'estimator__beta_2': 0.999, 'estimator__early_stopping': False, 'estimator__epsilon': 1e-08, 'estimator__hidden_layer_sizes': (100,), 'estimator__learning_rate': 'constant', 'estimator__learning_rate_init': 0.001, 'estimator__max_fun': 15000, 'estimator__max_iter': 1, 'estimator__momentum': 0.9, 'estimator__n_iter_no_change': 10, 'estimator__nesterovs_momentum': True, 'estimator__power_t': 0.5, 'estimator__random_state': None, 'estimator__shuffle': True, 'estimator__solver': 'adam', 'estimator__tol': 0.0001, 'estimator__validation_fraction': 0.1, 'estimator__verbose': False, 'estimator__warm_start': False, 'estimator': MLPClassifier(max_iter=1), 'n_jobs': None, 'param_grid': {'hidden_layer_sizes': [(30, 50), (10, 10, 10)], 'activation': ['logistic', 'tanh', 'relu', 'identity'], 'solver': ['sgd', 'adam']}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 0}
Confusion Matrix: 
[[1089   33    3    2   29    4    0   15   10    0    4    1    1    0
    36   40   73  710   26    0    1    6   38]
 [  43  751   10    2    5    0    2    4    3    0    3    1    1    0
     7   29   13  308    6    0    1    0   11]
 [  11   13  265   17    1    1    2   10    1    2    7   14    0    2
     3    6    4  631    4    0    3    7    5]
 [  22   47  108   34    9    8    3   13    2    2   17   30    0    5
    15    6   14 1280   12    0    8   13   15]
 [ 163   40   10    3  171   20    3    8    5    1   19    6    1    3
    16   27   29 1783   31    2    3    8   14]
 [  23    9    6    3    7   46    1    4    7    1    6    2    0    4
    11   21   14  485   39    0    7    9    3]
 [  13   20    9    3    4    1   54   46    3    0    7    1    1    2
     4    4    7  767    2    0    4    3    9]
 [  26   13   14    1    5    4    2  161    2    0    2    2    2    1
     2    3    9  885    9    0    5    7   20]
 [   8    9    0    2    5    1    0    3   89    0    1    0    1    2
     1    3    8  242   38    0    0    1    2]
 [  17   14   17    6    5    6    3    3    8    5    8    8    1    2
     3    4    9  769    5    1   14   41    8]
 [  20   36   35   12   27    6    6    4    8    2   49   19    0    3
    14    5    9 1235   13    1   10   18   10]
 [   3    4   49   14    4    0    1    1    2    1    6  101    0    4
     0    1    2  372    2    0    3    9    5]
 [  71   10    7    0    5    1    0   10    2    0    0    0   32    0
     9   51   14  325   11    0    0    1   23]
 [   1    8    5    2    2    3    2    1    1    0    3   10    0   75
     0    3    1  243    3    0    2    5    2]
 [  99    8    0    0    7    3    1    0    3    0    0    0    0    0
  1054   42    9  114   28    0   23    4    1]
 [  62  115    4    1    7    0    0    3    4    0    0    0    4    1
    22  247   56  300   11    0    0    3   10]
 [  60   14    3    1    7    0    0    4    0    0    2    0    0    0
     8   19  650  257    4    0    1    7    0]
 [ 277  237  143   27   92   37   21  152   52    6   47   31    4   18
    69  102  126 9316   79    5   32   61   51]
 [  40   14    4    1   12   14    1    3   20    2    6    1    1    2
    12   12   13  442  270    0    1    7    6]
 [  22   18   11    7   14    3    5    2    1    1    9    3    0    5
     4    5    7  763   10   10   12    5   26]
 [   0    5    0    0    1    1    2    1    2    0    2    2    0    0
     8    0    1  119    0    0  154   11    1]
 [   4    9   11    4    3    6    0    0    7    3    6    3    0    2
     8    7    4  485    7    0   67  157    4]
 [  44   13   13    1    2    0    2   17    2    0    1    1    2    1
     4   11    5  425    2    1    1    3  160]]
Classification Report: 
                precision    recall  f1-score   support

    admiration       0.50      0.51      0.51      2121
     amusement       0.52      0.63      0.57      1200
         anger       0.35      0.26      0.30      1009
     annoyance       0.23      0.02      0.04      1663
      approval       0.40      0.07      0.12      2366
        caring       0.27      0.06      0.10       708
     confusion       0.47      0.06      0.10       964
     curiosity       0.34      0.14      0.20      1175
        desire       0.38      0.21      0.27       416
disappointment       0.15      0.01      0.01       957
   disapproval       0.23      0.03      0.06      1542
       disgust       0.40      0.17      0.24       584
    excitement       0.63      0.06      0.10       572
          fear       0.52      0.20      0.29       372
     gratitude       0.80      0.76      0.78      1396
           joy       0.37      0.29      0.33       850
          love       0.60      0.63      0.61      1037
       neutral       0.41      0.85      0.55     10985
      optimism       0.44      0.31      0.36       884
   realization       0.50      0.01      0.02       943
       remorse       0.43      0.50      0.46       310
       sadness       0.39      0.20      0.26       797
      surprise       0.37      0.23      0.28       711

     micro avg       0.43      0.45      0.44     33562
     macro avg       0.42      0.27      0.29     33562
  weighted avg       0.42      0.45      0.37     33562

--------------------------------------------
Sentiment GridSearchCV(estimator=MLPClassifier(max_iter=1),
             param_grid={'activation': ['logistic', 'tanh', 'relu', 'identity'],
                         'hidden_layer_sizes': [(30, 50), (10, 10, 10)],
                         'solver': ['sgd', 'adam']}):{'cv': None, 'error_score': nan, 'estimator__activation': 'relu', 'estimator__alpha': 0.0001, 'estimator__batch_size': 'auto', 'estimator__beta_1': 0.9, 'estimator__beta_2': 0.999, 'estimator__early_stopping': False, 'estimator__epsilon': 1e-08, 'estimator__hidden_layer_sizes': (100,), 'estimator__learning_rate': 'constant', 'estimator__learning_rate_init': 0.001, 'estimator__max_fun': 15000, 'estimator__max_iter': 1, 'estimator__momentum': 0.9, 'estimator__n_iter_no_change': 10, 'estimator__nesterovs_momentum': True, 'estimator__power_t': 0.5, 'estimator__random_state': None, 'estimator__shuffle': True, 'estimator__solver': 'adam', 'estimator__tol': 0.0001, 'estimator__validation_fraction': 0.1, 'estimator__verbose': False, 'estimator__warm_start': False, 'estimator': MLPClassifier(max_iter=1), 'n_jobs': None, 'param_grid': {'hidden_layer_sizes': [(30, 50), (10, 10, 10)], 'activation': ['logistic', 'tanh', 'relu', 'identity'], 'solver': ['sgd', 'adam']}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 0}
Confusion Matrix: 
[[ 782  585 1846  580]
 [ 205 4178 2541  835]
 [ 474 1724 6712 2075]
 [ 243  936 2889 7759]]
Classification Report: 
              precision    recall  f1-score   support

   ambiguous       0.46      0.21      0.28      3793
    negative       0.56      0.54      0.55      7759
     neutral       0.48      0.61      0.54     10985
    positive       0.69      0.66      0.67     11827

    accuracy                           0.57     34364
   macro avg       0.55      0.50      0.51     34364
weighted avg       0.57      0.57      0.56     34364

--------------------------------------------
