Emotion MLPClassifier(max_iter=1):{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
Confusion Matrix: 
[[ 1009    22     2     0     1     1     0     4     3     0     1     0
      0     0    40    18    85   916    14     0     0     0     5]
 [   38   614     1     0     0     0     0     2     1     0     0     0
      0     0     5    17     9   508     2     0     0     0     3]
 [   12     8   171    12     0     0     0    10     0     0     7     3
      0     0     3     3     5   766     3     0     0     4     2]
 [   18    25    47    19     2     0     0    11     1     0    14     3
      1     0    12     2    12  1482     4     0     3     3     4]
 [  130    28     2     1    66     2     0     5     1     0    12     0
      1     0    18    13    28  2034    16     0     1     4     4]
 [   21     6     2     0     0    13     0     2     1     0     2     0
      0     0    14    14    15   569    37     0     4     6     2]
 [   10    21     7     0     0     0    18    26     0     0     5     0
      0     0     3     4     3   861     0     0     2     2     2]
 [   17     9    11     1     0     0     1   118     1     0     1     0
      0     0     2     1     6   999     3     0     3     1     1]
 [   11     8     0     0     0     0     0     3    41     0     0     0
      0     1     2     1     8   312    26     0     0     2     1]
 [    9     9     9     3     1     2     2     5     2     1     4     1
      0     0     2     2    11   861     4     0     4    19     6]
 [   15    21    15     1     9     0     3     2     0     0    42     2
      0     0    12     4     7  1390     9     0     4     4     2]
 [    9     1    21     3     0     0     0     0     1     0     6    35
      0     1     0     0     0   499     2     0     0     4     2]
 [   65     3     2     0     1     0     0     1     1     0     0     0
     11     0    10    33    11   422     9     0     0     0     3]
 [    6     9     3     0     2     0     0     2     0     0     1     1
      0    19     0     0     1   321     3     0     0     2     2]
 [   83     9     0     0     0     0     0     0     0     0     0     0
      0     0  1039    31    10   195    15     0     8     6     0]
 [   53    88     2     0     0     0     0     0     1     0     0     0
      1     1    28   168    60   441     5     0     0     1     1]
 [   42     9     2     0     2     0     0     3     0     0     0     0
      0     0     8     9   644   312     2     0     2     2     0]
 [  206   166    51     4    24     5     2    76    18     0    31     1
      1     1    62    55   115 10088    40     0     9    23     7]
 [   33     7     2     0     2     0     0     0     6     0     1     0
      1     0    15     3    13   609   188     0     0     3     1]
 [   16    11     3     0     1     0     1     1     0     0     4     1
      0     0     2     3     5   880     4     2     3     4     2]
 [    1     5     1     0     1     0     0     0     2     0     1     0
      0     0     4     0     1   201     0     0    57    36     0]
 [    6    12     5     1     0     1     0     0     2     0     3     1
      0     1     3     4     7   613     5     0    25   108     0]
 [   45     6    11     0     0     1     0    15     1     0     1     0
      1     0     5     7     4   554     1     0     0     2    57]]
Classification Report: 
                precision    recall  f1-score   support

    admiration       0.53      0.48      0.50      2121
     amusement       0.56      0.51      0.53      1200
         anger       0.45      0.17      0.25      1009
     annoyance       0.40      0.01      0.02      1663
      approval       0.58      0.03      0.05      2366
        caring       0.50      0.02      0.04       708
     confusion       0.64      0.02      0.04       964
     curiosity       0.41      0.10      0.16      1175
        desire       0.49      0.10      0.16       416
disappointment       1.00      0.00      0.00       957
   disapproval       0.30      0.03      0.05      1542
       disgust       0.73      0.06      0.11       584
    excitement       0.65      0.02      0.04       572
          fear       0.73      0.05      0.10       372
     gratitude       0.80      0.74      0.77      1396
           joy       0.41      0.20      0.27       850
          love       0.60      0.62      0.61      1037
       neutral       0.38      0.92      0.54     10985
      optimism       0.48      0.21      0.29       884
   realization       1.00      0.00      0.00       943
       remorse       0.43      0.18      0.26       310
       sadness       0.45      0.14      0.21       797
      surprise       0.53      0.08      0.14       711

     micro avg       0.42      0.43      0.43     33562
     macro avg       0.57      0.20      0.22     33562
  weighted avg       0.51      0.43      0.33     33562

--------------------------------------------
Sentiment MLPClassifier(max_iter=1):{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
Confusion Matrix: 
[[ 774  562 1821  636]
 [ 200 4017 2634  908]
 [ 468 1618 6742 2157]
 [ 227  834 2950 7816]]
Classification Report: 
              precision    recall  f1-score   support

   ambiguous       0.46      0.20      0.28      3793
    negative       0.57      0.52      0.54      7759
     neutral       0.48      0.61      0.54     10985
    positive       0.68      0.66      0.67     11827

    accuracy                           0.56     34364
   macro avg       0.55      0.50      0.51     34364
weighted avg       0.57      0.56      0.56     34364

--------------------------------------------
Emotion GridSearchCV(estimator=MLPClassifier(max_iter=1),
             param_grid={'activation': ['logistic', 'tanh', 'relu', 'identity'],
                         'hidden_layer_sizes': [(30, 50), (10, 10, 10)],
                         'solver': ['sgd', 'adam']}):{'cv': None, 'error_score': nan, 'estimator__activation': 'relu', 'estimator__alpha': 0.0001, 'estimator__batch_size': 'auto', 'estimator__beta_1': 0.9, 'estimator__beta_2': 0.999, 'estimator__early_stopping': False, 'estimator__epsilon': 1e-08, 'estimator__hidden_layer_sizes': (100,), 'estimator__learning_rate': 'constant', 'estimator__learning_rate_init': 0.001, 'estimator__max_fun': 15000, 'estimator__max_iter': 1, 'estimator__momentum': 0.9, 'estimator__n_iter_no_change': 10, 'estimator__nesterovs_momentum': True, 'estimator__power_t': 0.5, 'estimator__random_state': None, 'estimator__shuffle': True, 'estimator__solver': 'adam', 'estimator__tol': 0.0001, 'estimator__validation_fraction': 0.1, 'estimator__verbose': False, 'estimator__warm_start': False, 'estimator': MLPClassifier(max_iter=1), 'n_jobs': None, 'param_grid': {'hidden_layer_sizes': [(30, 50), (10, 10, 10)], 'activation': ['logistic', 'tanh', 'relu', 'identity'], 'solver': ['sgd', 'adam']}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 0}
Confusion Matrix: 
[[1091   25    2    0    0    3    0    5    1    0    1    0    0   35
    19   68  851   10    0    0   10]
 [  58  663    4    0    0    0    0    2    1    2    1    0    0    6
    11    6  441    1    0    1    3]
 [  13   12  251    2    0    0    0   11    0    5    5    0    0    4
     1    3  688    3    0   10    1]
 [  22   37   98    4    0    1    0   11    0   16   13    0    0   11
     2    9 1418    2    4   12    3]
 [ 153   32    8    0   13    3    0    2    0   15    3    0    0   16
    11   28 2060   12    0    6    4]
 [  30    8    6    0    0   22    0    0    1    2    0    0    0   15
     7   15  562   24    4   11    1]
 [  10   22   12    0    0    0    2   25    0   13    1    0    0    3
     2    4  861    0    2    5    2]
 [  26   11   22    0    0    0    0  104    0    0    2    0    0    2
     0    5  992    4    3    2    2]
 [  13    9    4    0    0    1    0    2   20    0    0    0    0    2
     2    7  314   27    0   13    2]
 [  14   28   28    2    6    0    0    1    0   40   10    0    0   12
     2    9 1356    8    2   22    2]
 [   8    3   44    2    0    0    0    3    0    9   60    0    0    0
     0    1  438    2    0   13    1]
 [ 102    9    4    0    0    0    0    3    1    0    0    1    0    6
    30   10  392    5    0    0    9]
 [   3    8   10    0    0    2    0    0    0    1    7    0    8    0
     2    3  290    9    0   27    2]
 [ 103    9    0    0    0    4    0    0    1    0    0    0    0 1027
    28   10  180   12    7   15    0]
 [  99  100    3    0    0    2    0    0    1    0    0    0    0   25
   134   45  428    7    0    3    3]
 [  91    8    2    0    0    1    0    0    0    0    1    0    0    9
     7  591  319    1    1    6    0]
 [ 309  176  107    2    3   17    0   76    3   43   11    0    0   57
    40   99 9917   36    8   69   12]
 [  41    9    5    0    0   11    0    1    1    2    0    0    0   13
     2   13  622  151    0   12    1]
 [   0    7    0    0    0    2    0    1    0    2    2    0    0    8
     0    1  148    0   52   87    0]
 [   4    9    6    1    0    4    0    0    2    9    3    0    0    8
     3    5  539    3   24  177    0]
 [  57   15   15    0    0    1    0   19    0    2    0    0    0    7
     5    2  517    0    1    5   65]]
Classification Report: 
              precision    recall  f1-score   support

  admiration       0.47      0.51      0.49      2121
   amusement       0.53      0.55      0.54      1200
       anger       0.37      0.25      0.30      1009
   annoyance       0.27      0.00      0.00      1663
    approval       0.59      0.01      0.01      2366
      caring       0.28      0.03      0.06       708
   confusion       1.00      0.00      0.00       964
   curiosity       0.38      0.09      0.14      1175
      desire       0.61      0.05      0.09       416
 disapproval       0.22      0.03      0.05      1542
     disgust       0.44      0.10      0.17       584
  excitement       1.00      0.00      0.00       572
        fear       1.00      0.02      0.04       372
   gratitude       0.80      0.74      0.76      1396
         joy       0.41      0.16      0.23       850
        love       0.62      0.57      0.59      1037
     neutral       0.39      0.90      0.54     10985
    optimism       0.46      0.17      0.25       884
     remorse       0.43      0.17      0.24       310
     sadness       0.30      0.22      0.26       797
    surprise       0.49      0.09      0.15       711

   micro avg       0.42      0.45      0.44     31662
   macro avg       0.53      0.22      0.23     31662
weighted avg       0.47      0.45      0.34     31662

--------------------------------------------
Sentiment GridSearchCV(estimator=MLPClassifier(max_iter=1),
             param_grid={'activation': ['logistic', 'tanh', 'relu', 'identity'],
                         'hidden_layer_sizes': [(30, 50), (10, 10, 10)],
                         'solver': ['sgd', 'adam']}):{'cv': None, 'error_score': nan, 'estimator__activation': 'relu', 'estimator__alpha': 0.0001, 'estimator__batch_size': 'auto', 'estimator__beta_1': 0.9, 'estimator__beta_2': 0.999, 'estimator__early_stopping': False, 'estimator__epsilon': 1e-08, 'estimator__hidden_layer_sizes': (100,), 'estimator__learning_rate': 'constant', 'estimator__learning_rate_init': 0.001, 'estimator__max_fun': 15000, 'estimator__max_iter': 1, 'estimator__momentum': 0.9, 'estimator__n_iter_no_change': 10, 'estimator__nesterovs_momentum': True, 'estimator__power_t': 0.5, 'estimator__random_state': None, 'estimator__shuffle': True, 'estimator__solver': 'adam', 'estimator__tol': 0.0001, 'estimator__validation_fraction': 0.1, 'estimator__verbose': False, 'estimator__warm_start': False, 'estimator': MLPClassifier(max_iter=1), 'n_jobs': None, 'param_grid': {'hidden_layer_sizes': [(30, 50), (10, 10, 10)], 'activation': ['logistic', 'tanh', 'relu', 'identity'], 'solver': ['sgd', 'adam']}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 0}
Confusion Matrix: 
[[ 760  574 1689  770]
 [ 165 4010 2476 1108]
 [ 430 1630 6332 2593]
 [ 198  792 2566 8271]]
Classification Report: 
              precision    recall  f1-score   support

   ambiguous       0.49      0.20      0.28      3793
    negative       0.57      0.52      0.54      7759
     neutral       0.48      0.58      0.53     10985
    positive       0.65      0.70      0.67     11827

    accuracy                           0.56     34364
   macro avg       0.55      0.50      0.51     34364
weighted avg       0.56      0.56      0.55     34364

--------------------------------------------
